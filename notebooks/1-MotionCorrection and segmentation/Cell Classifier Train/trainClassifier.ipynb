{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute with tf tensorflow env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_height = 172\n",
    "img_width = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1710 files belonging to 3 classes.\n",
      "Using 1368 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  './Dataset',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1710 files belonging to 3 classes.\n",
      "Using 342 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "   './Dataset',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 172, 216, 1)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this if you want to normalise the images\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.37254903\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both models work well, the first is muuuuuch smaller\n",
    "num_classes = 3\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    # 1st conv\n",
    "  tf.keras.layers.Conv2D(96, (11,11),strides=(4,4), activation='relu', input_shape=( img_height, img_width,1)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, strides=(2,2)),\n",
    "    # 2nd conv\n",
    "  tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "     # 3rd conv\n",
    "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "    # 4th conv\n",
    "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "    # 5th Conv\n",
    "  tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),\n",
    "  # To Flatten layer\n",
    "  tf.keras.layers.Flatten(),\n",
    "  # To FC layer 1\n",
    "  tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    # add dropout 0.5 ==> tf.keras.layers.Dropout(0.5),\n",
    "  #To FC layer 2\n",
    "  tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    # add dropout 0.5 ==> tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 6s 57ms/step - loss: 0.7029 - accuracy: 0.7295 - val_loss: 0.4949 - val_accuracy: 0.8246\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.5315 - accuracy: 0.8180 - val_loss: 0.4649 - val_accuracy: 0.8450\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.4812 - accuracy: 0.8392 - val_loss: 0.4273 - val_accuracy: 0.8567\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.4262 - accuracy: 0.8516 - val_loss: 0.4460 - val_accuracy: 0.8450\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.4026 - accuracy: 0.8560 - val_loss: 0.4458 - val_accuracy: 0.8392\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.3782 - accuracy: 0.8648 - val_loss: 0.3935 - val_accuracy: 0.8655\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.3511 - accuracy: 0.8787 - val_loss: 0.3761 - val_accuracy: 0.8830\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.3116 - accuracy: 0.8969 - val_loss: 0.3369 - val_accuracy: 0.8830\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.2633 - accuracy: 0.9064 - val_loss: 0.3306 - val_accuracy: 0.8860\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.2335 - accuracy: 0.9174 - val_loss: 0.3432 - val_accuracy: 0.8772\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.2033 - accuracy: 0.9262 - val_loss: 0.3467 - val_accuracy: 0.8772\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.1788 - accuracy: 0.9415 - val_loss: 0.3583 - val_accuracy: 0.8830\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.1553 - accuracy: 0.9496 - val_loss: 0.3891 - val_accuracy: 0.8801\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.1341 - accuracy: 0.9583 - val_loss: 0.4243 - val_accuracy: 0.8684\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.1167 - accuracy: 0.9620 - val_loss: 0.4265 - val_accuracy: 0.8713\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.1025 - accuracy: 0.9642 - val_loss: 0.4804 - val_accuracy: 0.8596\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.1063 - accuracy: 0.9620 - val_loss: 0.5160 - val_accuracy: 0.8509\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.1227 - accuracy: 0.9598 - val_loss: 0.5713 - val_accuracy: 0.8421\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.1420 - accuracy: 0.9437 - val_loss: 0.5415 - val_accuracy: 0.8626\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.1702 - accuracy: 0.9401 - val_loss: 0.4660 - val_accuracy: 0.8860\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.1178 - accuracy: 0.9605 - val_loss: 0.6041 - val_accuracy: 0.8860\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.1216 - accuracy: 0.9591 - val_loss: 0.4358 - val_accuracy: 0.8860\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0734 - accuracy: 0.9773 - val_loss: 0.5481 - val_accuracy: 0.8743\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0634 - accuracy: 0.9795 - val_loss: 0.5383 - val_accuracy: 0.8743\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0466 - accuracy: 0.9868 - val_loss: 0.5685 - val_accuracy: 0.8801\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0387 - accuracy: 0.9890 - val_loss: 0.6426 - val_accuracy: 0.8743\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.6628 - val_accuracy: 0.8772\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.7094 - val_accuracy: 0.8743\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.8189 - val_accuracy: 0.8713\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.7842 - val_accuracy: 0.8801\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.8017 - val_accuracy: 0.8801\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0316 - accuracy: 0.9876 - val_loss: 0.8186 - val_accuracy: 0.8743\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.9212 - val_accuracy: 0.8743\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.7384 - val_accuracy: 0.8801\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0432 - accuracy: 0.9868 - val_loss: 0.9367 - val_accuracy: 0.8655\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0438 - accuracy: 0.9832 - val_loss: 0.8102 - val_accuracy: 0.8684\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0475 - accuracy: 0.9803 - val_loss: 0.8021 - val_accuracy: 0.8801\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.8669 - val_accuracy: 0.8860\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.9214 - val_accuracy: 0.8596\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.7173 - val_accuracy: 0.8830\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0451 - accuracy: 0.9839 - val_loss: 0.9627 - val_accuracy: 0.8684\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0522 - accuracy: 0.9817 - val_loss: 0.6205 - val_accuracy: 0.8977\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.5651 - val_accuracy: 0.8713\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.6425 - val_accuracy: 0.8801\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m   train_ds,\n\u001b[0;32m      3\u001b[0m   validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[0;32m      4\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\LabAdmin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 =  tf.keras.models.load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
