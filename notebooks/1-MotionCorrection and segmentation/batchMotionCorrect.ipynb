{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion correction using CaImAn and pixel correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook performs batch motion correction on microscopy images using CaImAn and pixel value correction. It consists of three main sections:\n",
    "\n",
    "Generate list of files:\n",
    "Loads experiment metadata from Excel files specified in fileHeader\n",
    "Creates lists of input files that need motion correction (files with \"jumpCorrected.tif\" but no \"mc.tif\" version)\n",
    "Stores file paths and fps (frames per second) information\n",
    "Motion correction:\n",
    "Uses CaImAn's MotionCorrect to perform non-rigid motion correction on each file\n",
    "\n",
    "\n",
    "Pixel value correction:\n",
    "Corrects pixel intensity values that were altered during motion correction\n",
    "For each motion corrected file:\n",
    "Reads both original and motion corrected images\n",
    "Computes average pixel value difference in a ROI (20-80% of image)\n",
    "If difference >= 10:\n",
    "Adjusts motion corrected image by subtracting/adding the difference\n",
    "Saves corrected file\n",
    "If difference < 10:\n",
    "Assumes file already corrected\n",
    "\n",
    "\n",
    "CaImAn for motion correction\n",
    "tifffile for reading/writing TIFF files\n",
    "pandas for handling metadata\n",
    "numpy for array operations\n",
    "The code is designed to process microscopy data from various experiments involving calcium imaging of inner hair cells (IHCs), spiral ganglion neurons (SGNs), and calcium waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "parameterFolder = '../parameters/'\n",
    "\n",
    "# Select appropriate set of experiments, uncomment as required.\n",
    "fileHeader = [\n",
    "#'6N',\n",
    "#'Atoh1_IHCs',\n",
    "'Myo15_IHCs',\n",
    "#'Myo15_IHCs_post-hearing',\n",
    "#'NeuroD_SGN',\n",
    "#'NeuroD_SGN_ex_vivo'\n",
    "#'Pax2_Calciumwaves',\n",
    "#'Pax2_Calciumwaves_broken',\n",
    "# 'Pax2_Calciumwaves_post-hearing',\n",
    "#'Snap25_SGN',\n",
    "#'CavKO',\n",
    "#'Otof KO',\n",
    "#'FVB',\n",
    "  ]\n",
    "\n",
    "alldata = pd.DataFrame()\n",
    "for h in fileHeader:\n",
    "    inputFilename = os.path.join('../../',h)+'.xlsx'\n",
    "\n",
    "    alldata1 = pd.read_excel(inputFilename)\n",
    "    alldata = alldata.append(alldata1[alldata1['discard']!=1],ignore_index=True)\n",
    "\n",
    "alldata = alldata[~alldata['Folder'].isna()]\n",
    "alldata = alldata.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Generate the list of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all the files that need to be motion corrected. This list contains the files that have a \"jumpcorrected\" file but not a motion corrected (mc) file. If a recording has a mc file in its folder is not going to be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "localDrive = 'E' # Select the drive where the data is saved in. \n",
    "localfolders = [localDrive+el[1:] for el in alldata['Folder']]\n",
    "fpss = alldata['fps']\n",
    "allfilesToCorrect = []\n",
    "allinputFiles = []\n",
    "allfps = []\n",
    "for j,el in enumerate(localfolders):\n",
    "  for (dirpath, dirnames, filenames) in os.walk(el):\n",
    "\n",
    "    for name in filenames:\n",
    "      if name =='1-jumpCorrected.tif':\n",
    "        infile = os.path.join(dirpath, name)\n",
    "        outFile = os.path.join(dirpath, '1-jumpCorrected-mc.tif')\n",
    "        if not os.path.exists(outFile): \n",
    "          \n",
    "          allfilesToCorrect.append(outFile) \n",
    "          allinputFiles.append(infile)\n",
    "          allfps.append(fpss[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that does the motion correction (from CaImAn examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bpl\n",
    "import cv2\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "bpl.output_notebook()\n",
    "\n",
    "import tifffile\n",
    "\n",
    "def caimanMC(inFile,outFile,fps):\n",
    "    fnames = [inFile]\n",
    "    # dataset dependent parameters\n",
    "    fr = fps                            # imaging rate in frames per second\n",
    "    decay_time = 1                  # length of a typical transient in seconds\n",
    "\n",
    "    # motion correction parameters\n",
    "    strides = (96, 96)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "    overlaps = (24*2, 24*2)         # overlap between pathes (size of patch strides+overlaps)\n",
    "    max_shifts = (50,50)#(20,20)#(6,6)          # maximum allowed rigid shifts (in pixels)\n",
    "    max_deviation_rigid = 25#10     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "    pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "    # parameters for source extraction and deconvolution\n",
    "    p = 1                       # order of the autoregressive system\n",
    "    gnb = 2                     # number of global background components\n",
    "    merge_thr = 0.85            # merging threshold, max correlation allowed\n",
    "    rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "    stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "    K = 4                       # number of components per patch\n",
    "    gSig = [4, 4]               # expected half size of neurons in pixels\n",
    "    method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "    ssub = 1                    # spatial subsampling during initialization\n",
    "    tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "    # parameters for component evaluation\n",
    "    min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "    rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "    cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "    cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n",
    "    opts_dict = {'fnames': fnames,\n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'gSig': gSig,\n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest}\n",
    "\n",
    "    opts = params.CNMFParams(params_dict=opts_dict)\n",
    "\n",
    "    #%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "    if 'dview' in locals():\n",
    "        cm.stop_server(dview=dview)\n",
    "    c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "        backend='local', n_processes=None, single_thread=False)\n",
    "    # first we create a motion correction object with the parameters specified\n",
    "    mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
    "    # note that the file is not loaded in memory\n",
    "    mc.motion_correct(save_movie=True)\n",
    "    m_els = cm.load(mc.fname_tot_els)\n",
    "    border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0 \n",
    "        # maximum shift to be used for trimming against NaNs\n",
    "    m_els2 = m_els.copy()\n",
    "    m_els2[m_els2<0]=0\n",
    "    m_els2 = m_els2.astype(np.uint16)\n",
    "    tifffile.imwrite(outFile, m_els2)\n",
    "    cm.stop_server(dview=dview)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Actual motion correction. \n",
    "The mmap files generated by CaIman are deleted at the end, as they can be very big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,el in enumerate(allinputFiles):\n",
    "    print(el)\n",
    "    print(i)\n",
    "    caimanMC(el,allfilesToCorrect[i],allfps[i])\n",
    "\n",
    "    localfolders = [localDrive+el[1:] for el in alldata['Folder']]\n",
    "    filestoRemove = []\n",
    "    \n",
    "    for el in localfolders:\n",
    "        for (dirpath, dirnames, filenames) in os.walk(el):\n",
    "\n",
    "            for name in filenames:\n",
    "                if name.endswith('.mmap'):\n",
    "                    print(dirpath)\n",
    "                    os.remove(os.path.join(dirpath,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Correction of pixel values for motion corrected tiff files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CaIman alters the pixel value so that their distribution is different from the one of the original recording. We adjust the values by adding (or subtracting) the difference between the average pixel values in the mc recording compared to the original. Note that the jumpCorrected file must be present in the same folder of the mc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterFolder = '../../parameters/'\n",
    "fileHeader = [\n",
    "#'6N',\n",
    "#'Atoh1_IHCs',\n",
    "'Myo15_IHCs',\n",
    "#'Myo15_IHCs_post-hearing',\n",
    "#'NeuroD_SGN',\n",
    "#'NeuroD_SGN_ex_vivo'\n",
    "#'Pax2_Calciumwaves',\n",
    "#'Pax2_Calciumwaves_broken',\n",
    "# 'Pax2_Calciumwaves_post-hearing',\n",
    "#'Snap25_SGN',\n",
    "#'CavKO',\n",
    "#'Otof KO',\n",
    "#'FVB',\n",
    "  ]\n",
    "\n",
    "alldata = pd.DataFrame()\n",
    "for h in fileHeader:\n",
    "    inputFilename = os.path.join('../../',h)+'.xlsx'\n",
    "\n",
    "    alldata1 = pd.read_excel(inputFilename)\n",
    "    alldata = alldata.append(alldata1[alldata1['discard']!=1],ignore_index=True)\n",
    "\n",
    "alldata = alldata[~alldata['Folder'].isna()]\n",
    "alldata = alldata.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "localDrive = 'E' # Drive where the files are. Change Accordingly\n",
    "localfolders = [localDrive+el[1:] for el in alldata['Folder']]\n",
    "fpss = alldata['fps']\n",
    "allfilesToCorrect = []\n",
    "allinputFiles = []\n",
    "allOrigFiles = []\n",
    "allfps = []\n",
    "for j,el in enumerate(localfolders):\n",
    "  \n",
    "    for (dirpath, dirnames, filenames) in os.walk(el):\n",
    "\n",
    "      for name in filenames:\n",
    "        if name =='1-jumpCorrected-mc.tif':\n",
    "          infile = os.path.join(dirpath, name)\n",
    "\n",
    "          outFile = os.path.join(dirpath, '1-jumpCorrected-mc.tif')\n",
    "          orig = os.path.join(dirpath, '1-jumpCorrected.tif')\n",
    "          if os.path.exists(infile):\n",
    "            allOrigFiles.append(orig)\n",
    "            allfilesToCorrect.append(outFile) \n",
    "            allinputFiles.append(infile)\n",
    "            allfps.append(fpss[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allinputFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfilesToCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allOrigFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,el in enumerate(allinputFiles):\n",
    "    \"\"\"\n",
    "    This script processes a list of input TIFF files, performs motion correction, and saves the corrected files if necessary.\n",
    "    For each file in `allinputFiles`:\n",
    "    1. Reads the motion-corrected TIFF file.\n",
    "    2. Attempts to read the corresponding original (non-motion-corrected) TIFF file.\n",
    "    3. If the original file is found:\n",
    "        - Defines a region of interest (ROI) within the image.\n",
    "        - Computes the difference (correction) between the motion-corrected and original images within the ROI.\n",
    "        - If the mean correction value is significant (>= 10), adjusts the motion-corrected image by the mean correction value and saves the corrected image.\n",
    "        - If the mean correction value is not significant, assumes the file is already corrected and prints a message.\n",
    "\n",
    "    Libraries:\n",
    "    - `tifffile`: Used for reading and writing TIFF files.\n",
    "    \"\"\"\n",
    "    print(el)\n",
    "    print(i)\n",
    "    mcOriginal = tifffile.imread(el)\n",
    "    try:\n",
    "        notMCOriginal = tifffile.imread(allOrigFiles[i])\n",
    "    except FileNotFoundError:\n",
    "        print('Not found on local drive, tring the server')\n",
    "        notMCOriginal = None\n",
    "        \n",
    "    if notMCOriginal is not None:\n",
    "        xl1 = int(mcOriginal.shape[1]*0.2)\n",
    "        xl2 = int(mcOriginal.shape[1]*0.8)\n",
    "\n",
    "        yl1 = int(mcOriginal.shape[2]*0.2)\n",
    "        yl2 = int(mcOriginal.shape[2]*0.8)\n",
    "\n",
    "        corr = mcOriginal[:100,xl1:xl2,yl1:yl2].astype(float64)-notMCOriginal[:100,xl1:xl2,yl1:yl2].astype(float64)\n",
    "        print(corr.mean())\n",
    "        if abs(corr.mean())>=10:\n",
    "            mcOriginal = mcOriginal.astype(float64) - corr.mean()\n",
    "            tifffile.imwrite(allfilesToCorrect[i],mcOriginal.astype(uint16))\n",
    "            print(allfilesToCorrect[i])\n",
    "            print('\\n\\n')\n",
    "        else:\n",
    "            print('File probably already corrected, double check')\n",
    "            print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa8522bbf777dbdc3b75aca28b76ffd20090ed2cb5a7bbfec3f96c0aba2c60d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
